{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c1e5cd",
   "metadata": {},
   "source": [
    "# 1. Working with Environment Variables Using os and dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af2c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import os is used in Python to work with the operating system — especially for tasks related to file handling, environment \n",
    "variables, paths, and system-level operations.\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "print(os.getenv(\"LANGCHAIN_PROJECT\"))\n",
    "\n",
    "# Set environment variables in the OS environment (local environment keys are loaded)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Langsmith tracking and tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81473d76",
   "metadata": {},
   "source": [
    "# 2. Initializing and Using LangChain OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3bd329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x107947c90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x107a14d50> root_client=<openai.OpenAI object at 0x10721d3d0> root_async_client=<openai.AsyncOpenAI object at 0x107a14a90> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "content='**Agentic AI** refers to artificial intelligence systems designed with a degree of autonomy and agency, enabling them to make decisions, take actions, and pursue goals with minimal human intervention. The concept draws from the idea of \"agency\" in psychology and philosophy, which pertains to the capacity to act independently and make choices.\\n\\n### Key Characteristics of Agentic AI:\\n\\n1. **Autonomy:** Agentic AI systems can operate independently, making decisions without needing constant human guidance.\\n\\n2. **Goal-Oriented Behavior:** These AI agents are programmed or trained to achieve specific objectives, adapting their actions based on feedback and changing environments.\\n\\n3. **Perception and Sensing:** They possess the ability to perceive their environment through various sensors or data inputs, allowing them to gather information necessary for decision-making.\\n\\n4. **Adaptability:** Agentic AI can adjust its strategies and actions in response to new information, learning from experiences to improve performance over time.\\n\\n5. **Interaction:** These systems can interact with other agents, humans, or environments, often communicating and collaborating to achieve their goals.\\n\\n### Examples of Agentic AI:\\n\\n- **Autonomous Vehicles:** Self-driving cars navigate roads, make real-time decisions to ensure safety, and optimize routes without direct human control.\\n\\n- **Virtual Assistants:** Advanced AI assistants like Siri or Alexa not only respond to commands but can proactively suggest actions based on user behavior and preferences.\\n\\n- **Robotic Process Automation (RPA):** Robots in manufacturing settings that adjust their operations based on sensor data and optimize production processes autonomously.\\n\\n- **Intelligent Virtual Agents:** Bots used in customer service that can handle complex queries, learn from interactions, and improve their responses over time.\\n\\n### Potential Implications:\\n\\n1. **Efficiency and Productivity:** Agentic AI can perform tasks more quickly and accurately than humans in certain contexts, leading to significant gains in efficiency.\\n\\n2. **Ethical Considerations:** As AI agents become more autonomous, questions arise about accountability, decision-making transparency, and ethical behavior, especially in critical fields like healthcare or law enforcement.\\n\\n3. **Employment Impact:** Increased automation may lead to shifts in the job market, with certain roles becoming obsolete while new opportunities emerge in AI management and oversight.\\n\\n4. **Security Risks:** Autonomous AI systems could be targets for manipulation or could make unintended decisions that have significant consequences if not properly controlled.\\n\\n### Future Outlook:\\n\\nThe development of Agentic AI is a significant area of research and innovation, aiming to create more sophisticated and reliable autonomous systems. Advances in machine learning, robotics, and cognitive computing are driving this field forward. However, balancing the benefits with ethical considerations and ensuring robust governance frameworks will be crucial as Agentic AI becomes increasingly integrated into various aspects of society.\\n\\n---\\n\\n**In Summary:** Agentic AI embodies the next step in artificial intelligence evolution, where systems are not just tools responding to commands but active agents capable of independent action and decision-making. This shift holds immense promise for numerous applications but also necessitates careful consideration of the accompanying ethical, social, and technical challenges.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 874, 'prompt_tokens': 13, 'total_tokens': 887, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BrGx3kJko0nQSq6uodcjW9Yr6BWIf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--aa1c5575-99e9-4f8e-8082-d6c366640ee1-0' usage_metadata={'input_tokens': 13, 'output_tokens': 874, 'total_tokens': 887, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}\n",
      "**Agentic AI** refers to artificial intelligence systems designed with a degree of autonomy and agency, enabling them to make decisions, take actions, and pursue goals with minimal human intervention. The concept draws from the idea of \"agency\" in psychology and philosophy, which pertains to the capacity to act independently and make choices.\n",
      "\n",
      "### Key Characteristics of Agentic AI:\n",
      "\n",
      "1. **Autonomy:** Agentic AI systems can operate independently, making decisions without needing constant human guidance.\n",
      "\n",
      "2. **Goal-Oriented Behavior:** These AI agents are programmed or trained to achieve specific objectives, adapting their actions based on feedback and changing environments.\n",
      "\n",
      "3. **Perception and Sensing:** They possess the ability to perceive their environment through various sensors or data inputs, allowing them to gather information necessary for decision-making.\n",
      "\n",
      "4. **Adaptability:** Agentic AI can adjust its strategies and actions in response to new information, learning from experiences to improve performance over time.\n",
      "\n",
      "5. **Interaction:** These systems can interact with other agents, humans, or environments, often communicating and collaborating to achieve their goals.\n",
      "\n",
      "### Examples of Agentic AI:\n",
      "\n",
      "- **Autonomous Vehicles:** Self-driving cars navigate roads, make real-time decisions to ensure safety, and optimize routes without direct human control.\n",
      "\n",
      "- **Virtual Assistants:** Advanced AI assistants like Siri or Alexa not only respond to commands but can proactively suggest actions based on user behavior and preferences.\n",
      "\n",
      "- **Robotic Process Automation (RPA):** Robots in manufacturing settings that adjust their operations based on sensor data and optimize production processes autonomously.\n",
      "\n",
      "- **Intelligent Virtual Agents:** Bots used in customer service that can handle complex queries, learn from interactions, and improve their responses over time.\n",
      "\n",
      "### Potential Implications:\n",
      "\n",
      "1. **Efficiency and Productivity:** Agentic AI can perform tasks more quickly and accurately than humans in certain contexts, leading to significant gains in efficiency.\n",
      "\n",
      "2. **Ethical Considerations:** As AI agents become more autonomous, questions arise about accountability, decision-making transparency, and ethical behavior, especially in critical fields like healthcare or law enforcement.\n",
      "\n",
      "3. **Employment Impact:** Increased automation may lead to shifts in the job market, with certain roles becoming obsolete while new opportunities emerge in AI management and oversight.\n",
      "\n",
      "4. **Security Risks:** Autonomous AI systems could be targets for manipulation or could make unintended decisions that have significant consequences if not properly controlled.\n",
      "\n",
      "### Future Outlook:\n",
      "\n",
      "The development of Agentic AI is a significant area of research and innovation, aiming to create more sophisticated and reliable autonomous systems. Advances in machine learning, robotics, and cognitive computing are driving this field forward. However, balancing the benefits with ethical considerations and ensuring robust governance frameworks will be crucial as Agentic AI becomes increasingly integrated into various aspects of society.\n",
      "\n",
      "---\n",
      "\n",
      "**In Summary:** Agentic AI embodies the next step in artificial intelligence evolution, where systems are not just tools responding to commands but active agents capable of independent action and decision-making. This shift holds immense promise for numerous applications but also necessitates careful consideration of the accompanying ethical, social, and technical challenges.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize OpenAI LLM client (using a smaller or custom model)\n",
    "llm = ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n",
    "\n",
    "# Using the client\n",
    "result = llm.invoke(\"What is Agentic AI?\")\n",
    "print(result)\n",
    "print(result.content)  # Access the text content from the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91557594",
   "metadata": {},
   "source": [
    "## 🔑 Here's what you need:\n",
    "\n",
    "| Key                     | Required? | Why?                                                  |\n",
    "|-------------------------|-----------|--------------------------------------------------------|\n",
    "| **OpenAI API Key** (`OPENAI_API_KEY`) | ✅ Yes    | To access OpenAI models like `gpt-3.5-turbo`, `gpt-4`, etc. |\n",
    "| **LangChain API Key**              | ❌ No     | Not needed unless you're using LangSmith or LangChainHub features |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205bef7",
   "metadata": {},
   "source": [
    "# 3. Using Groq Open-Source Models with ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cba7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, the user said, \"Hi My name is Ankita.\" I need to respond appropriately. Let me start by greeting her back. Maybe say \"Hello, Ankita!\" to acknowledge her name. Then, I should ask how I can assist her today. Keep it friendly and open-ended so she feels comfortable to ask for help. I should make sure the tone is positive and welcoming. Let me check if there\\'s anything else to consider. No, that\\'s straightforward. Just a simple greeting and offer of help. Alright, that should work.\\n\\nWait, maybe I can add an emoji to make it more personable? Like a smiley? Hmm, the user didn\\'t use any emojis, but maybe it\\'s okay. Alternatively, just keep it text-based. Let me go with the initial idea. Keep it professional yet friendly.\\n</think>\\n\\nHello Ankita! Nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 16, 'total_tokens': 223, 'completion_time': 0.503049735, 'prompt_time': 0.003104769, 'queue_time': 0.016391439, 'total_time': 0.506154504}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None} id='run--5d75205d-beb2-463c-9af9-77cc0b9a6800-0' usage_metadata={'input_tokens': 16, 'output_tokens': 207, 'total_tokens': 223}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize Groq model client (does not query on initialization)\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "\n",
    "# Invoke the model with a prompt\n",
    "response = model.invoke(\"Hi My name is Ankita\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91142ebb",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Use ChatGroq with GROQ_API_KEY to access open-source Groq-hosted models.\n",
    "\n",
    "- No LangChain API key needed unless using LangSmith or LangChainHub.\n",
    "\n",
    "- Groq models are different from OpenAI's GPT models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6780be",
   "metadata": {},
   "source": [
    "# 4. Prompt Engineering Using ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a03d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI Engineer, I can definitely tell you about Langsmith! \n",
      "\n",
      "Langsmith is an open-source platform developed by the team at Replicate that aims to simplify the process of building and deploying AI applications, particularly those leveraging large language models (LLMs). \n",
      "\n",
      "Here's a breakdown of key aspects of Langsmith:\n",
      "\n",
      "**Core Features:**\n",
      "\n",
      "* **Simplified LLM Interaction:** Langsmith provides a user-friendly interface for interacting with various LLMs, abstracting away the complexities of API calls and model management.\n",
      "\n",
      "* **Easy Prompt Engineering:** It offers tools and techniques to help you craft effective prompts, leading to better performance from your chosen LLM.\n",
      "\n",
      "* **Pipeline Creation:** You can chain together multiple LLMs or other AI components to build sophisticated workflows for tasks like text summarization, question answering, code generation, and more.\n",
      "\n",
      "* **Model Management:** Langsmith helps you version, track, and manage different LLM models within your projects.\n",
      "* **Deployment:** It makes it relatively straightforward to deploy your AI applications, whether you want to share them publicly or keep them private.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Accessibility:** Langsmith lowers the barrier to entry for developers who want to utilize LLMs but may not have deep expertise in AI or specialized infrastructure.\n",
      "* **Efficiency:** It streamlines the development process, allowing you to focus on building your application logic rather than getting bogged down in technical details.\n",
      "* **Collaboration:** Langsmith's open-source nature fosters collaboration and community contributions, leading to ongoing improvements and a wider range of available tools.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "You can find more information and get started with Langsmith at its official website: [https://www.langsmith.ai/](https://www.langsmith.ai/)\n",
      "\n",
      "Let me know if you have any more specific questions about Langsmith. I'm happy to provide more details or examples based on your interests!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Chaining prompt and model\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me something about Langsmith\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd59cdc",
   "metadata": {},
   "source": [
    "### 🧩 What’s Happening Here:\n",
    "\n",
    "| Message Type | Purpose                                                                                     |\n",
    "|--------------|---------------------------------------------------------------------------------------------|\n",
    "| **system**   | Gives the model a role and behavior. In this case: pretend to be an **AI expert**.           |\n",
    "| **user**     | Represents the **user input**. The `{input}` is a **placeholder** that will be replaced with the actual question when the prompt is used. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6c20d",
   "metadata": {},
   "source": [
    "# 5. Using Output Parsers for Clean Output\n",
    "## 5.1 String Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec8a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're in luck! As an AI Engineer, I'm quite familiar with Langsmith.  \n",
      "\n",
      "Langsmith is an open-source tool designed to simplify the process of fine-tuning and deploying large language models (LLMs).  Think of it as a platform that bridges the gap between powerful pre-trained LLMs and real-world applications.\n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Simplified Fine-Tuning:** Langsmith streamlines the fine-tuning process, making it more accessible to developers without extensive machine learning expertise. It offers a user-friendly interface and pre-configured workflows for common fine-tuning tasks.\n",
      "* **Model Hub:** It provides a repository of pre-trained LLMs from various sources, allowing users to easily choose and experiment with different models.\n",
      "* **Deployment Flexibility:** Langsmith supports deploying fine-tuned models in different environments, including cloud platforms and on-premise servers. It offers options for both batch and real-time inference.\n",
      "* **Data Management:**  It includes tools for managing and preprocessing training data, ensuring data quality and efficiency.\n",
      "* **Open-Source and Community-Driven:** Being open-source, Langsmith benefits from a vibrant community of developers who contribute to its development and provide support.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Democratization of LLMs:** Langsmith makes it easier for a wider range of developers and organizations to leverage the power of LLMs for their specific needs.\n",
      "* **Faster Development Cycles:** The streamlined workflows and pre-built components accelerate the development and deployment of LLM-powered applications.\n",
      "* **Cost-Effectiveness:** By simplifying fine-tuning and deployment, Langsmith can help reduce the costs associated with using LLMs.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "If you're interested in exploring Langsmith, check out their official website and documentation: [https://github.com/langsmithai/langsmith](https://github.com/langsmithai/langsmith) \n",
      "\n",
      "They provide detailed instructions, tutorials, and examples to get you started.\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or anything else related to AI!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me something about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6537a",
   "metadata": {},
   "source": [
    "## 5.2 JSON Output Parser with PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5c09d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for developing and deploying large language models (LLMs).', 'features': ['**Model Development:** Provides tools and infrastructure for training, fine-tuning, and evaluating LLMs.', '**Model Deployment:** Enables easy deployment of trained models as APIs or web services.', '**Model Sharing:** Facilitates sharing and collaboration on LLM models within the community.', '**Customizable Workflows:** Allows users to build and customize their own LLM development workflows.', '**Open-Source and Community-Driven:** Built on open-source principles and actively developed by a community of contributors.'], 'website': 'https://github.com/langs-team/langs'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query\\n{format_instruction}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "response = chain.invoke({\"query\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295d938",
   "metadata": {},
   "source": [
    "## 5.3 JSON Output Parser with ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide the response in json. Provide me answer based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c91e5",
   "metadata": {},
   "source": [
    "## 5.4 XML Output Parser with PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52d78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'name': 'Langsmith'}, {'description': 'Langsmith is an open-source platform designed to help developers build and deploy AI-powered applications. It provides a range of tools and services, including a code generation engine, a model library, and a deployment platform.'}, {'features': [{'feature': 'Code Generation'}, {'feature': 'Model Library'}, {'feature': 'Deployment Platform'}]}, {'website': 'https://www.langs.ml/'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"query\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d353b",
   "metadata": {},
   "source": [
    "## 5.5 XML Output Parser with ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: defusedxml\n",
      "Successfully installed defusedxml-0.7.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install defusedxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f0ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'answer': '\\nLangsmith is an open-source platform developed by Google DeepMind that aims to simplify the process of fine-tuning large language models (LLMs). It provides a user-friendly interface and tools to make it easier for researchers and developers to adapt pre-trained LLMs to specific tasks without requiring extensive technical expertise. \\n'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe19e13",
   "metadata": {},
   "source": [
    "# 6. With Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022d781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c82b8",
   "metadata": {},
   "source": [
    "# 7. Without Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db175e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't scientists trust atoms? Because they make up everything!\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_query = \"Tell me a joke .\"\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3db91",
   "metadata": {},
   "source": [
    "# 8. YAML Output Parser with Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e683a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why couldn't the bicycle find its way home?\", punchline='Because it lost its bearings!')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": \"Tell me a joke\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bc0e1",
   "metadata": {},
   "source": [
    "# 9. Assignment:\n",
    "## Create a simple assistant that uses any LLM and should be pydantic.\n",
    "## When we ask about any product, it should return:\n",
    "### - product name\n",
    "### - product details\n",
    "### - tentative price in USD (integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0490a1e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
